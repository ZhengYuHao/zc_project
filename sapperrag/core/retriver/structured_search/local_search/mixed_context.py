from __future__ import annotations

import logging
from typing import Any
import pandas as pd
import tiktoken

from ....retriver.context_builder.builders import LocalContextBuilder
from ....retriver.context_builder.entity_extraction import map_query_to_entities
from ....retriver.context_builder.entity_context import build_entity_context
from ....retriver.context_builder.relationship_context import build_relationship_context
from ....retriver.context_builder.community_context import build_community_context
from ....retriver.context_builder.source_context import build_source_context

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LocalSearchMixedContext(LocalContextBuilder):
    def __init__(self, entities, relationships, community_reports):
        self.entities = entities
        self.relationships = relationships
        self.community_reports = community_reports

    async def build_context(self, extracted_entities: list, level:int, infer: bool, api_key: str, base_url:str, **kwargs: Any) -> Any:
        """
        æ„å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡

        :param extracted_entities: æŠ½å–åˆ°çš„å®ä½“åˆ—è¡¨
        :param level: æŸ¥è¯¢æ·±åº¦
        :param infer: æ˜¯å¦è¿›è¡Œæ¨ç†
        :param kwargs: å…¶ä»–å‚æ•°
        """
        token_encoder = tiktoken.get_encoding("cl100k_base")
        selected_entities = await map_query_to_entities(extracted_entities, self.entities, api_key, base_url, k=10)
        logger.info(f"å·²åŒ¹é…åˆ°å®ä½“ğŸ˜Š")

        human_read_id = 0 # ç”¨äºæ›¿æ¢å¤æ‚çš„ID,æ–¹ä¾¿æ¨¡å‹æº¯æº
        final_context = list[str]()
        final_context_data = dict[str, pd.DataFrame]()

        # community_context, community_context_data, human_read_id = build_community_context(self.community_reports,
        #                                                                     selected_entities=selected_entities,
        #                                                                     token_encoder=token_encoder,
        #                                                                     human_read_id=human_read_id,
        #                                                                     user_level=level,
        #                                                                     infer=infer)
        #
        # if community_context.strip() != "":
        #     final_context.append(str(community_context))
        #     final_context_data["Reports"] = community_context_data
        # logger.info(f"ç¤¾åŒºæ–‡æœ¬å·²æ£€ç´¢å®ŒæˆğŸ˜Š")
        #
        # entity_context, entity_context_data, human_read_id = build_entity_context(selected_entities, token_encoder=token_encoder, human_read_id=human_read_id)
        #
        # if entity_context.strip() != "":
        #     final_context.append(str(entity_context))
        #     final_context_data["Entities"] = entity_context_data
        # logger.info(f"å®ä½“æ–‡æœ¬å·²æ£€ç´¢å®ŒæˆğŸ˜Š")

        selected_relationships, relationship_context, relationship_context_data, human_read_id = build_relationship_context(
            selected_entities=selected_entities,
            token_encoder=token_encoder,
            relationships=self.relationships,
            entities=self.entities,
            human_read_id=human_read_id)

        # if relationship_context.strip() != "":
        #     final_context.append(str(relationship_context))
        #     final_context_data["Relationships"] = relationship_context_data
        # logger.info(f"å…³ç³»æ–‡æœ¬å·²æ£€ç´¢å®ŒæˆğŸ˜Š")

        source_context, source_context_data, human_read_id = build_source_context(selected_relationships=selected_relationships,
                                                                                  token_encoder=token_encoder,
                                                                                  human_read_id=human_read_id)

        if source_context.strip() != "":
            final_context.append(str(source_context))
            final_context_data["Sources"] = source_context_data
        logger.info(f"æ¥æºæ–‡æœ¬å·²æ£€ç´¢å®ŒæˆğŸ˜Š")

        return "\n\n".join(final_context), final_context_data